# ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

## ğŸ“‹ í•„ìˆ˜ ì‚¬í•­

- Python 3.11+
- Docker & Docker Compose (í”„ë¡œë•ì…˜ìš©)
- Git
- GPU (ì„ íƒì‚¬í•­, í•˜ì§€ë§Œ ê¶Œì¥ë¨)

## ğŸš€ 5ë¶„ ì•ˆì— ì‹œì‘í•˜ê¸°

### ë°©ë²• 1: Docker Compose (ê¶Œì¥)

```bash
# 1. í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd /Users/iyeonglag/PycharmProjects/2025-2-CSC4004-1-3-Fithub

# 2. .env íŒŒì¼ ìƒì„±
cp .env.example .env

# 3. ëª¨ë“  ì„œë¹„ìŠ¤ ì‹œì‘
docker-compose up -d

# 4. í—¬ìŠ¤ ì²´í¬
curl http://localhost:8000/health

# 5. API ë¬¸ì„œ ë³´ê¸°
# http://localhost:8000/docs (Swagger UI)
```

### ë°©ë²• 2: ë¡œì»¬ ì‹¤í–‰ (ê°œë°œìš©)

```bash
# 1. ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# 2. MCP ì„œë¹„ìŠ¤ ì‹œì‘ (í„°ë¯¸ë„ 1-5)
python -m uvicorn mcp.summarization.main:app --port 9001
python -m uvicorn mcp.structural_analysis.main:app --port 9002
python -m uvicorn mcp.semantic_embedding.main:app --port 9003
python -m uvicorn mcp.repository_analysis.main:app --port 9004
python -m uvicorn mcp.task_recommender.main:app --port 9005

# 3. Agent Service ì‹œì‘ (í„°ë¯¸ë„ 6)
python -m uvicorn agent.main:app --port 8000
```

## ğŸ§  AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì„¤ì •

### ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸

```python
# setup_models.py ì‹¤í–‰
python setup_models.py
```

ë˜ëŠ” ìˆ˜ë™ìœ¼ë¡œ:

```python
from transformers import AutoModel, AutoTokenizer
import os

# ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs('models/summarization', exist_ok=True)

# CodeT5+ ë‹¤ìš´ë¡œë“œ
model = AutoModel.from_pretrained(
    'Salesforce/codet5p-base',
    cache_dir='models/summarization'
)
tokenizer = AutoTokenizer.from_pretrained(
    'Salesforce/codet5p-base',
    cache_dir='models/summarization'
)

print("âœ“ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
```

## ğŸ“Š ì²« ë²ˆì§¸ ë¶„ì„ ì‹¤í–‰

### 1. ê³µê°œ ì €ì¥ì†Œ ë¶„ì„

```bash
curl -X POST http://localhost:8000/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "repo": {
      "source": "git",
      "uri": "https://github.com/pallets/flask",
      "branch": "main"
    },
    "options": {
      "summary": "llm",
      "graph": "full",
      "metrics": "full"
    }
  }'
```

### 2. ë¡œì»¬ ì €ì¥ì†Œ ë¶„ì„

```bash
curl -X POST http://localhost:8000/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "repo": {
      "source": "local",
      "uri": "/path/to/your/repo"
    }
  }'
```

### 3. ë¹„ë™ê¸° ë¶„ì„ (ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì €ì¥ì†Œ)

```bash
# ë¶„ì„ ì‹œì‘
curl -X POST http://localhost:8000/analyze-async \
  -H "Content-Type: application/json" \
  -d '{
    "repo": {
      "source": "git",
      "uri": "https://github.com/torvalds/linux"
    }
  }'

# ì‘ë‹µ: {"run_id": "abc-123", "status": "queued"}

# ê²°ê³¼ ì¡°íšŒ
curl http://localhost:8000/result/abc-123

# HTML ë¦¬í¬íŠ¸
curl http://localhost:8000/report/abc-123 > report.html
```

## ğŸ”§ ëª¨ë¸ í†µí•©í•˜ê¸°

ë‹¹ì‹ ì˜ ì»¤ìŠ¤í…€ ëª¨ë¸ì„ Summarization MCPì— ì¶”ê°€:

### 1. models_loader.py ìˆ˜ì •

```python
# mcp/summarization/models_loader.py

class SummarizationModelPool:
    def initialize(self):
        # ê¸°ì¡´ ì½”ë“œ...

        # ë‹¹ì‹ ì˜ ì»¤ìŠ¤í…€ ëª¨ë¸ ì¶”ê°€
        try:
            self.pool.add_model(
                "my_custom_model",
                "/path/to/local/model",  # ë˜ëŠ” HuggingFace ID
                model_type="transformer"
            )
            logger.info("âœ“ My Custom Model loaded")
        except Exception as e:
            logger.warning(f"Failed to load: {e}")
```

### 2. summarizer.py ìˆ˜ì •

```python
# mcp/summarization/summarizer.py

def _generate_summary(self, code: str, model_name: str = "codebert") -> str:
    """ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""

    if model_name == "my_custom_model":
        # ë‹¹ì‹ ì˜ ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œì§
        model, tokenizer, name = self.model_pool.pool.get_model("my_custom_model"), ...

        # ëª¨ë¸ ì¶”ë¡  ë¡œì§
        inputs = tokenizer(code, return_tensors="pt", max_length=512, truncation=True)
        outputs = model(**inputs)

        # ê²°ê³¼ ì²˜ë¦¬
        summary = "ìƒì„±ëœ ìš”ì•½..."
        return summary

    # ê¸°ì¡´ ë¡œì§...
```

## ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸

```bash
# ëª¨ë“  ì„œë¹„ìŠ¤ ìƒíƒœ
curl http://localhost:8000/mcp-status

# Agent Service ë¡œê·¸
docker logs agent-service -f

# íŠ¹ì • MCP ë¡œê·¸
docker logs summarization-mcp -f
```

## ğŸ› ë¬¸ì œ í•´ê²°

### "Connection refused" ì˜¤ë¥˜
```bash
# MCP ì„œë¹„ìŠ¤ê°€ ì‹œì‘ë˜ì—ˆëŠ”ì§€ í™•ì¸
curl http://localhost:9001/health

# Dockerì—ì„œ ì‹¤í–‰ ì¤‘ì´ë©´
docker ps | grep mcp
```

### ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜
```bash
# HuggingFace í† í° ì„¤ì •
huggingface-cli login

# ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export HF_TOKEN=your_token_here
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# CPU ì „ìš©ìœ¼ë¡œ ì‹¤í–‰
export DEVICE=cpu

# ë°°ì¹˜ í¬ê¸° ê°ì†Œ (mcp/*/main.pyì—ì„œ)
# batch_size = 4  # ê¸°ë³¸ê°’ì—ì„œ ê°ì†Œ
```

## ğŸ“š ë‹¤ìŒ ë‹¨ê³„

1. **êµ¬ì¡° ì´í•´**: `structure.md` ì½ê¸°
2. **API íƒìƒ‰**: `http://localhost:8000/docs` (Swagger UI)
3. **ëª¨ë¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•**: ë‹¹ì‹ ì˜ ëª¨ë¸ í†µí•©
4. **ë°°í¬**: Docker Composeë¥¼ AWS/GCP/Azureì— ë°°í¬
5. **ì„±ëŠ¥ ìµœì í™”**: GPU í™œì„±í™”, ë°°ì¹˜ ì²˜ë¦¬, ìºì‹±

## ğŸ†˜ ì§€ì›

- ë¬¸ì œ ë°œìƒ ì‹œ: `README.md`ì˜ "ë¬¸ì œ í•´ê²°" ì„¹ì…˜ ì°¸ê³ 
- ìƒì„¸ ë¬¸ì„œ: `structure.md`
- API ë¬¸ì„œ: `http://localhost:8000/docs`
