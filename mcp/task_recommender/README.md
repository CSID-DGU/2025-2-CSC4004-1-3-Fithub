# MCP Task Recommender - ì‘ì—… ì¶”ì²œ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤

## ğŸ“‹ ê°œìš”

**Task Recommender MCP**ëŠ” ë¶„ì„ëœ ì½”ë“œ, ê·¸ë˜í”„, ë©”íƒ€ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°œì„  ì‘ì—…ì„ ì¶”ì²œí•©ë‹ˆë‹¤.

- **í¬íŠ¸:** 9005 (FastAPI)
- **ì—­í• :** "Action Provider" - ê°œì„  ë°©ì•ˆ ì œì‹œ
- **ì¶œë ¥:** 5ê°€ì§€ ì¹´í…Œê³ ë¦¬ì˜ ìš°ì„ ìˆœìœ„ ì‘ì—… ëª©ë¡

---

## ğŸ¯ ì¶”ì²œ ì¹´í…Œê³ ë¦¬

| ì¹´í…Œê³ ë¦¬ | ëª©í‘œ | ì˜ˆì‹œ |
|---------|------|------|
| **ë³µì¡ë„ ê°œì„ ** | ìˆœí™˜ ì˜ì¡´ì„±, ìˆœí™˜ ì°¸ì¡° ì œê±° | "Refactor circular imports in auth_service â†” db_model" |
| **ì˜ì¡´ì„± ìµœì í™”** | ê°•í•œ ê²°í•©ë„ ë¶„ë¦¬ | "Decouple database from service layer" |
| **í’ˆì§ˆ í–¥ìƒ** | ë¬¸ì„œí™”, íƒ€ì… íŒíŠ¸, ëª…ëª… ê·œì¹™ | "Add docstrings to 12 public functions" |
| **êµ¬ì¡° ê°œì„ ** | ì•„í‚¤í…ì²˜ ìœ„ë°˜ ìˆ˜ì • | "Service layer should not import from view layer" |
| **ì„±ëŠ¥ ìµœì í™”** | ë³‘ëª© ì§€ì  ì œê±° | "Optimize N+1 query in user_fetch function" |

---

## ğŸ“‚ íŒŒì¼ êµ¬ì¡°

```
mcp/task_recommender/
â”œâ”€â”€ main.py                 # FastAPI ì„œë²„ ë° ì—”ë“œí¬ì¸íŠ¸ âœ…
â”œâ”€â”€ recommender.py          # TaskRecommender í´ë˜ìŠ¤ âš ï¸ (ë¶€ë¶„ êµ¬í˜„)
â”œâ”€â”€ models_loader.py        # ëª¨ë¸ í’€ (CodeT5) ğŸ“
â”œâ”€â”€ requirements.txt        # ì˜ì¡´ì„± âœ…
â”œâ”€â”€ Dockerfile              # ì»¨í…Œì´ë„ˆ ë¹Œë“œ âœ…
â””â”€â”€ README.md               # ì´ ë¬¸ì„œ
```

---

## âš™ï¸ êµ¬í˜„ ìƒíƒœ ë° í•„ìš” ì‘ì—…

### âš ï¸ ê¸´ê¸‰ í•„ìš” ì‘ì—…

#### **Task 1: `recommender.py` - 5ê°œ ë¶„ì„ ë©”ì„œë“œ ì™„ì„±**

**íŒŒì¼:** `mcp/task_recommender/recommender.py`

```python
def recommend_tasks(self, graph: dict, metadata: dict, summaries: list) -> list[dict]:
    """
    ëª¨ë“  ë¶„ì„ ì‹¤í–‰ ë° ì‘ì—… ì¶”ì²œ

    Returns:
    [
        {
            "type": "refactor_circular_dependencies",
            "severity": "high",
            "description": "Circular imports detected between auth_service.py and db_model.py",
            "affected_files": ["auth_service.py", "db_model.py"],
            "effort_estimate": "medium",  # low, medium, high
            "impact_estimate": "high",     # low, medium, high
            "priority_score": 0.92,
            "suggested_actions": [
                "Extract shared interfaces to a separate module",
                "Implement dependency injection pattern",
                "Use type stubs for breaking circular imports"
            ]
        },
        ...
    ]
    """

    # 1ï¸âƒ£ ë³µì¡ë„ ë¶„ì„
    complexity_tasks = self._analyze_complexity(graph)

    # 2ï¸âƒ£ ì˜ì¡´ì„± ë¶„ì„
    dependency_tasks = self._analyze_dependencies(graph, summaries)

    # 3ï¸âƒ£ í’ˆì§ˆ ë¶„ì„
    quality_tasks = self._analyze_quality(summaries)

    # 4ï¸âƒ£ êµ¬ì¡° ê°œì„  ë¶„ì„
    structure_tasks = self._suggest_structure_improvements(metadata)

    # 5ï¸âƒ£ ì„±ëŠ¥ ë¶„ì„
    performance_tasks = self._analyze_performance(graph, summaries)

    # ëª¨ë“  ì‘ì—… í†µí•©
    all_tasks = (
        complexity_tasks +
        dependency_tasks +
        quality_tasks +
        structure_tasks +
        performance_tasks
    )

    # ìš°ì„ ìˆœìœ„ ì •ë ¬
    ranked_tasks = self._rank_recommendations(all_tasks)

    return ranked_tasks
```

**ê° ë©”ì„œë“œ êµ¬í˜„:**

##### **1ï¸âƒ£ `_analyze_complexity()` - ë³µì¡ë„ ë¶„ì„**

```python
def _analyze_complexity(self, graph: dict) -> list[dict]:
    """
    ìˆœí™˜ ì˜ì¡´ì„±, ìˆœí™˜ ì°¸ì¡° íƒì§€

    Returns:
    [
        {
            "type": "refactor_circular_dependencies",
            "severity": "high",
            "affected_files": ["A.py", "B.py"],
            "cycles": [["A.py::func1", "B.py::func2", "A.py::func1"]],
            "effort_estimate": "medium"
        },
        {
            "type": "decompose_large_files",
            "severity": "medium",
            "affected_files": ["services/auth.py"],  # 500+ lines
            "current_lines": 523,
            "effort_estimate": "medium"
        }
    ]
    """

    tasks = []

    # ìˆœí™˜ ì˜ì¡´ì„± íƒì§€
    edges = graph.get("edges", [])
    node_graph = self._build_adjacency_list(edges)
    cycles = self._find_cycles(node_graph)

    if cycles:
        cycle_files = set()
        for cycle in cycles:
            for node in cycle:
                file_name = node.split("::")[0]
                cycle_files.add(file_name)

        tasks.append({
            "type": "refactor_circular_dependencies",
            "severity": "high",
            "description": f"{len(cycles)} circular dependencies detected",
            "affected_files": list(cycle_files),
            "cycles": cycles,
            "effort_estimate": "medium",
            "impact_estimate": "high",
            "suggested_actions": [
                "Use dependency injection to break cycles",
                "Extract shared utilities to separate module",
                "Reorganize package structure"
            ]
        })

    # ëŒ€í˜• íŒŒì¼ ë¶„í•´
    nodes = graph.get("nodes", [])
    for node in nodes:
        if node.get("type") == "file":
            # íŒŒì¼ í¬ê¸° ê³„ì‚° (ìì‹ ë…¸ë“œ ìˆ˜ë¡œ ì¶”ì •)
            child_count = len(node.get("children", []))
            if child_count > 15:  # 15ê°œ ì´ìƒì˜ í•¨ìˆ˜/í´ë˜ìŠ¤
                tasks.append({
                    "type": "decompose_large_files",
                    "severity": "medium" if child_count < 25 else "high",
                    "description": f"File {node['label']} has {child_count} functions/classes",
                    "affected_files": [node["id"]],
                    "item_count": child_count,
                    "effort_estimate": "high",
                    "impact_estimate": "medium"
                })

    return tasks
```

##### **2ï¸âƒ£ `_analyze_dependencies()` - ì˜ì¡´ì„± ë¶„ì„**

```python
def _analyze_dependencies(self, graph: dict, summaries: list) -> list[dict]:
    """
    ê°•í•œ ê²°í•©ë„, ë†’ì€ íŒ¬ì¸/íŒ¬ì•„ì›ƒ íƒì§€
    """

    tasks = []
    edges = graph.get("edges", [])

    # ê° ë…¸ë“œì˜ íŒ¬ì¸/íŒ¬ì•„ì›ƒ ê³„ì‚°
    fan_in = {}
    fan_out = {}

    for edge in edges:
        source = edge.get("source")
        target = edge.get("target")

        fan_out[source] = fan_out.get(source, 0) + 1
        fan_in[target] = fan_in.get(target, 0) + 1

    # ë†’ì€ íŒ¬ì•„ì›ƒ (ë§ì´ ì˜ì¡´) íƒì§€
    high_fanout = {k: v for k, v in fan_out.items() if v > 5}
    if high_fanout:
        for file, count in sorted(high_fanout.items(), key=lambda x: -x[1])[:3]:
            tasks.append({
                "type": "reduce_coupling",
                "severity": "medium",
                "description": f"{file} has high fan-out ({count} dependencies)",
                "affected_files": [file],
                "dependency_count": count,
                "effort_estimate": "high",
                "impact_estimate": "high"
            })

    # ë†’ì€ íŒ¬ì¸ (ë§ì´ ì˜ì¡´ë¨) íƒì§€
    high_fanin = {k: v for k, v in fan_in.items() if v > 8}
    if high_fanin:
        for file, count in sorted(high_fanin.items(), key=lambda x: -x[1])[:2]:
            tasks.append({
                "type": "stabilize_core_module",
                "severity": "low",
                "description": f"{file} is a core module (used by {count} files)",
                "affected_files": [file],
                "dependents_count": count,
                "effort_estimate": "low",
                "impact_estimate": "high"
            })

    return tasks
```

##### **3ï¸âƒ£ `_analyze_quality()` - í’ˆì§ˆ ë¶„ì„**

```python
def _analyze_quality(self, summaries: list) -> list[dict]:
    """
    ë¬¸ì„œí™”, ëª…ëª… ê·œì¹™, ì¤‘ë³µ ì½”ë“œ íƒì§€
    """

    tasks = []
    undocumented_count = 0

    for summary in summaries:
        desc = summary.get("summary", "")

        # ë¬¸ì„œí™” ë¶€ì¬ íƒì§€
        if not desc or len(desc) < 20:
            undocumented_count += 1

        # ê¸°ìˆ  ë¶€ì±„ ì‹ í˜¸
        if any(word in desc.lower() for word in ["todo", "fixme", "hack", "temporary"]):
            tasks.append({
                "type": "resolve_technical_debt",
                "severity": "medium",
                "description": f"Technical debt marker found in {summary.get('file_id')}",
                "affected_files": [summary.get("file_id")],
                "effort_estimate": "medium"
            })

    # ëŒ€ëŸ‰ ë¯¸ë¬¸ì„œí™”
    if undocumented_count > len(summaries) * 0.3:  # 30% ì´ìƒ
        tasks.append({
            "type": "improve_documentation",
            "severity": "medium",
            "description": f"{undocumented_count} files lack documentation",
            "affected_files_count": undocumented_count,
            "effort_estimate": "high",
            "impact_estimate": "medium"
        })

    return tasks
```

##### **4ï¸âƒ£ `_suggest_structure_improvements()` - êµ¬ì¡° ê°œì„ **

```python
def _suggest_structure_improvements(self, metadata: dict) -> list[dict]:
    """
    ì•„í‚¤í…ì²˜ ìœ„ë°˜ íƒì§€ (ê³„ì¸µ ìœ„ë°˜ ë“±)
    """

    tasks = []
    file_metadata = metadata.get("file_metadata", {})

    # ê³„ì¸µ ê·œì¹™ ì •ì˜
    layer_rules = {
        "View": {"can_import": ["View", "Util"]},
        "Controller": {"can_import": ["Service", "Util"]},
        "Service": {"can_import": ["Model", "Repository", "Util"]},
        "Repository": {"can_import": ["Model", "Util"]},
        "Model": {"can_import": ["Util"]},
        "Util": {"can_import": ["Util"]}
    }

    # ìœ„ë°˜ íƒì§€
    logical_edges = metadata.get("logical_edges", [])

    for edge in logical_edges:
        source = edge.get("source")
        target = edge.get("target")

        source_meta = file_metadata.get(source, {})
        target_meta = file_metadata.get(target, {})

        source_layer = source_meta.get("layer")
        target_layer = target_meta.get("layer")

        if source_layer in layer_rules:
            allowed = layer_rules[source_layer].get("can_import", [])
            if target_layer not in allowed:
                tasks.append({
                    "type": "fix_layer_violation",
                    "severity": "high",
                    "description": f"{source_layer} layer should not import {target_layer} layer",
                    "affected_files": [source, target],
                    "violation": f"{source_layer} â†’ {target_layer}",
                    "effort_estimate": "high"
                })

    return tasks
```

##### **5ï¸âƒ£ `_analyze_performance()` - ì„±ëŠ¥ ë¶„ì„**

```python
def _analyze_performance(self, graph: dict, summaries: list) -> list[dict]:
    """
    N+1 ì¿¼ë¦¬, ë¹„íš¨ìœ¨ì  ìˆœíšŒ ë“± ì„±ëŠ¥ ë¬¸ì œ íƒì§€
    """

    tasks = []

    for summary in summaries:
        desc = summary.get("summary", "").lower()

        # N+1 ì¿¼ë¦¬ íŒ¨í„´ íƒì§€
        if any(word in desc for word in ["loop", "while", "for", "iterate"]):
            if any(word in desc for word in ["query", "fetch", "select", "find"]):
                tasks.append({
                    "type": "optimize_n_plus_1_query",
                    "severity": "medium",
                    "description": f"Potential N+1 query pattern in {summary.get('file_id')}",
                    "affected_files": [summary.get("file_id")],
                    "effort_estimate": "medium",
                    "impact_estimate": "high"
                })

        # ë¶ˆí•„ìš”í•œ ë³µì‚¬ íƒì§€
        if "copy" in desc and ("large" in desc or "array" in desc):
            tasks.append({
                "type": "optimize_memory_allocation",
                "severity": "low",
                "description": f"Potential inefficient memory usage in {summary.get('file_id')}",
                "affected_files": [summary.get("file_id")],
                "effort_estimate": "low"
            })

    return tasks
```

##### **6ï¸âƒ£ `_rank_recommendations()` - ìš°ì„ ìˆœìœ„ ì •ë ¬**

```python
def _rank_recommendations(self, tasks: list) -> list[dict]:
    """
    ì‘ì—… ìš°ì„ ìˆœìœ„ ê³„ì‚° ë° ì •ë ¬
    """

    # ì‹¬ê°ë„ ì ìˆ˜
    severity_scores = {
        "high": 10,
        "medium": 5,
        "low": 1
    }

    # ì˜í–¥ë„ ì ìˆ˜
    impact_scores = {
        "high": 10,
        "medium": 5,
        "low": 1
    }

    # ë…¸ë ¥ë„ ì ìˆ˜ (ì—­í•¨ìˆ˜: ë‚®ì„ìˆ˜ë¡ ìš°ì„ )
    effort_scores = {
        "low": 10,
        "medium": 5,
        "high": 1
    }

    for task in tasks:
        severity = severity_scores.get(task.get("severity", "medium"), 5)
        impact = impact_scores.get(task.get("impact_estimate", "medium"), 5)
        effort = effort_scores.get(task.get("effort_estimate", "medium"), 5)

        # ìš°ì„ ìˆœìœ„ = (ì‹¬ê°ë„ + ì˜í–¥ë„) * ë…¸ë ¥ ì—­í•¨ìˆ˜
        priority_score = ((severity + impact) / 2) * effort / 10
        task["priority_score"] = min(1.0, priority_score)

    # ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì •ë ¬
    ranked = sorted(tasks, key=lambda x: -x.get("priority_score", 0))

    return ranked
```

---

## ğŸ“¡ API ì—”ë“œí¬ì¸íŠ¸

### 1. ì‘ì—… ì¶”ì²œ

```bash
POST /recommend

{
  "graph": {
    "nodes": [...],
    "edges": [...]
  },
  "metadata": {
    "file_metadata": {...},
    "logical_edges": [...]
  },
  "summaries": [...]
}

Response:
{
  "recommendations": [
    {
      "type": "refactor_circular_dependencies",
      "severity": "high",
      "description": "...",
      "affected_files": ["auth_service.py", "db_model.py"],
      "priority_score": 0.95,
      "effort_estimate": "medium",
      "impact_estimate": "high",
      "suggested_actions": [...]
    },
    ...
  ],
  "total_tasks": 12,
  "execution_time": 3.45
}
```

### 2. í—¬ìŠ¤ ì²´í¬

```bash
GET /health

Response:
{
  "status": "healthy"
}
```

---

## ğŸš€ ì‹¤í–‰ ë°©ë²•

```bash
cd mcp/task_recommender
pip install -r requirements.txt
python -m uvicorn main:app --port 9005 --reload
```

---

## ğŸ“ ê°œë°œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] `_analyze_complexity()` êµ¬í˜„
  - [ ] ìˆœí™˜ ì˜ì¡´ì„± íƒì§€ (DFS)
  - [ ] ëŒ€í˜• íŒŒì¼ ë¶„í•´ ì œì•ˆ

- [ ] `_analyze_dependencies()` êµ¬í˜„
  - [ ] íŒ¬ì¸/íŒ¬ì•„ì›ƒ ê³„ì‚°
  - [ ] ë†’ì€ ê²°í•©ë„ íƒì§€

- [ ] `_analyze_quality()` êµ¬í˜„
  - [ ] ë¯¸ë¬¸ì„œí™” íƒì§€
  - [ ] ê¸°ìˆ  ë¶€ì±„ ì‹ í˜¸

- [ ] `_suggest_structure_improvements()` êµ¬í˜„
  - [ ] ê³„ì¸µ ìœ„ë°˜ íƒì§€
  - [ ] ì•„í‚¤í…ì²˜ ê·œì¹™ ê²€ì¦

- [ ] `_analyze_performance()` êµ¬í˜„
  - [ ] N+1 ì¿¼ë¦¬ íŒ¨í„´
  - [ ] ë©”ëª¨ë¦¬ ë¹„íš¨ìœ¨

- [ ] `_rank_recommendations()` êµ¬í˜„
  - [ ] ìš°ì„ ìˆœìœ„ ê³„ì‚°
  - [ ] ì •ë ¬

- [ ] ë¡œì»¬ í…ŒìŠ¤íŠ¸
- [ ] Docker ë¹Œë“œ

---

**ì°¸ê³ :** ìì„¸í•œ ë‚´ìš©ì€ `IMPLEMENTATION_STATUS.md` â†’ Task 6ì„ ì°¸ì¡°í•˜ì„¸ìš”.