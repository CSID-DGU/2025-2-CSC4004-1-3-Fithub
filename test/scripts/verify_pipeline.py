import asyncio
import time
import os
import sys
import logging
from agent.state import AgentState
from unittest.mock import MagicMock, patch

# Add project root to sys.path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))

from agent.workflow import get_workflow
from agent.config import Config

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Mock InferenceClient to avoid API calls
mock_client = MagicMock()
mock_client.text_generation.return_value = "This is a dummy summary."
mock_client.feature_extraction.return_value = [0.1] * 768 # Dummy embedding

# Mock OpenAI Client
mock_openai = MagicMock()
mock_openai.chat.completions.create.return_value.choices[0].message.content = '{"file_metadata": {}, "logical_edges": []}'

# Patching modules
patch('huggingface_hub.InferenceClient', return_value=mock_client).start()
patch('mcp.summarization.summarizer.InferenceClient', return_value=mock_client).start()
patch('mcp.semantic_embedding.embedder.InferenceClient', return_value=mock_client).start()
patch('mcp.repository_analysis.analyzer.InferenceClient', return_value=mock_client).start()
patch('mcp.repository_analysis.analyzer.OpenAI', return_value=mock_openai).start()

# Force OpenAI Provider
Config.LLM_PROVIDER = "openai"
Config.OPENAI_API_KEY = "sk-dummy"

async def run_verification():
    print("ğŸš€ Starting Verification Pipeline...")
    
    # 1. ì´ˆê¸° ìƒíƒœ ì„¤ì •
    initial_state: AgentState = {
        "run_id": "verify_test_run",
        "repo_input": {"repo_id": "test_repo", "branch": "main"},
        "options": {},
        "thresholds": {},
        "retry_count": 0,
        "initial_summaries": [],
        "embeddings": [],
        "code_graph_raw": {},
        "fused_data_package": {},
        "context_metadata": {},
        "final_graph_json": {},
        "metrics": {},
        "recommendations": [],
        "node_execution_log": []
    }

    # 2. ë¶„ì„ ì‹¤í–‰ (ì§ì ‘ í˜¸ì¶œ)
    # _run_analysisëŠ” ë¹„ë™ê¸° í•¨ìˆ˜ì´ë¯€ë¡œ await í•„ìš”
    # execution_storeëŠ” main.pyì— ì „ì—­ìœ¼ë¡œ ìˆì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì§ì ‘ stateë¥¼ í™•ì¸
    
    from agent.workflow import get_workflow
    workflow = get_workflow()
    
    print("ğŸ”„ Invoking Workflow...")
    final_state = await workflow.ainvoke(initial_state)
    
    print("âœ… Workflow Completed!")
    
    # 3. ê²°ê³¼ ê²€ì¦
    print("\nğŸ“Š Verification Results:")
    
    # A. RepoGraph & GNN Check
    graph_json = final_state.get("final_graph_json", {})
    nodes = graph_json.get("nodes", [])
    edges = graph_json.get("edges", [])
    
    print(f" - Nodes: {len(nodes)}")
    print(f" - Edges: {len(edges)}")
    
    # ì¤‘ìš”ë„(Size)ê°€ ë°˜ì˜ë˜ì—ˆëŠ”ì§€ í™•ì¸
    sizes = [n['size'] for n in nodes]
    if sizes:
        print(f" - Node Sizes: {sizes}")
        if max(sizes) > 30: # ê¸°ë³¸ê°’ì´ 30ì´ë¯€ë¡œ, ì¤‘ìš”ë„ê°€ ë°˜ì˜ë˜ë©´ ë” ì»¤ì•¼ í•¨
            print("   âœ… RepoGraph Importance Reflected (Size > 30)")
        else:
            print("   âš ï¸ RepoGraph Importance NOT Reflected (All default size)")
            
    # B. RepoCoder Check
    # ë…¼ë¦¬ì  ì—£ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
    logical_edges = [e for e in edges if e.get('type') == 'logical']
    print(f" - Logical Edges: {len(logical_edges)}")
    if logical_edges:
         print("   âœ… RepoCoder Logic Reflected (Logical edges found)")
    else:
         print("   âš ï¸ RepoCoder Logic NOT Reflected (No logical edges)")

    # C. LLM Check
    # ë„ë©”ì¸ íƒœê·¸ í™•ì¸
    domains = set(n.get('color') for n in nodes)
    print(f" - Domains (Colors): {domains}")

if __name__ == "__main__":
    asyncio.run(run_verification())
