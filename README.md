# LangGraph ê¸°ë°˜ ì½”ë“œ ë¶„ì„ AI ì—ì´ì „íŠ¸

LangGraphë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¢…í•©ì ì¸ ì½”ë“œ ë¶„ì„ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. GitHub, ZIP, ë¡œì»¬ ì €ì¥ì†Œì—ì„œ ì½”ë“œë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ê³ , êµ¬ì¡°, ìš”ì•½, ì˜ë¯¸ ì„ë² ë”©, í’ˆì§ˆ ë©”íŠ¸ë¦­ì„ ìƒì„±í•©ë‹ˆë‹¤.

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Client / Backend            â”‚
â”‚     (POST /analyze)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Agent Service (FastAPI + LangGraph)            â”‚
â”‚  - Workflow orchestration                        â”‚
â”‚  - State management                              â”‚
â”‚  - API endpoints                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼          â–¼          â–¼          â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Summary  â”‚ â”‚Struct  â”‚ â”‚Semanticâ”‚ â”‚Repo    â”‚ â”‚Task      â”‚
â”‚MCP      â”‚ â”‚Analysisâ”‚ â”‚Embeddingâ”‚ â”‚Analysisâ”‚ â”‚Recommender
â”‚(9001)   â”‚ â”‚(9002)  â”‚ â”‚(9003)  â”‚ â”‚(9004)  â”‚ â”‚(9005)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ ì£¼ìš” êµ¬ì„± ìš”ì†Œ

### 1. Agent Service (`agent/`)
- **main.py**: FastAPI ì„œë²„ ë° REST API ì—”ë“œí¬ì¸íŠ¸
- **workflow.py**: LangGraph ì›Œí¬í”Œë¡œìš° ì •ì˜
- **nodes.py**: ê° ë¶„ì„ ë…¸ë“œ í•¨ìˆ˜
- **edges.py**: ì¡°ê±´ë¶€ ë¼ìš°íŒ… ë¡œì§
- **state.py**: AgentState ì •ì˜
- **schemas.py**: Pydantic ë°ì´í„° ëª¨ë¸

### 2. MCP Services (`mcp/`)
- **Summarization** (Port 9001): ì½”ë“œ ìš”ì•½ ìƒì„±
- **Structural Analysis** (Port 9002): ì½”ë“œ êµ¬ì¡° ë¶„ì„
- **Semantic Embedding** (Port 9003): ì˜ë¯¸ ê¸°ë°˜ ì„ë² ë”©
- **Repository Analysis** (Port 9004): ì €ì¥ì†Œ ë ˆë²¨ ë¶„ì„
- **Task Recommender** (Port 9005): ì‘ì—… ì¶”ì²œ

### 3. Shared Utilities (`shared/`)
- **model_utils.py**: ëª¨ë¸ ë¡œë”© ë° ìºì‹±
- **git_utils.py**: Git ì €ì¥ì†Œ ê´€ë¦¬
- **ast_utils.py**: ì½”ë“œ ë¶„ì„ (AST íŒŒì‹±)

### 4. Models Cache (`models/`)
ë‹¹ì‹ ì´ ë‹¤ìš´ë¡œë“œí•œ AI ëª¨ë¸ë“¤ì„ ì €ì¥í•˜ëŠ” ë””ë ‰í† ë¦¬:
```
models/
â”œâ”€â”€ summarization/          # CodeT5+, StarCoder2, CodeLlama ë“±
â”œâ”€â”€ structural_analysis/    # GraphCodeBERT, CodeBERT
â”œâ”€â”€ semantic_embedding/     # CodeBERT, CuBERT
â”œâ”€â”€ repository_analysis/    # ì €ì¥ì†Œ ë¶„ì„ ëª¨ë¸
â””â”€â”€ task_recommender/       # ì¶”ì²œ ëª¨ë¸
```

## ğŸš€ ì„¤ì¹˜ ë° ì‹¤í–‰

### 1. ë¡œì»¬ ì‹¤í–‰ (ê°œë°œ)

```bash
# 1. ì €ì¥ì†Œ í´ë¡ 
git clone <repo_url>
cd 2025-2-CSC4004-1-3-Fithub

# 2. Python ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# 3. ê° MCP ì„œë¹„ìŠ¤ ì‹¤í–‰ (ë³„ë„ í„°ë¯¸ë„ì—ì„œ)
python -m uvicorn mcp.summarization.main:app --host 0.0.0.0 --port 9001
python -m uvicorn mcp.structural_analysis.main:app --host 0.0.0.0 --port 9002
python -m uvicorn mcp.semantic_embedding.main:app --host 0.0.0.0 --port 9003
python -m uvicorn mcp.repository_analysis.main:app --host 0.0.0.0 --port 9004
python -m uvicorn mcp.task_recommender.main:app --host 0.0.0.0 --port 9005

# 4. Agent Service ì‹¤í–‰
python -m uvicorn agent.main:app --host 0.0.0.0 --port 8000
```

### 2. Dockerë¡œ ì‹¤í–‰ (í”„ë¡œë•ì…˜)

```bash
# .env íŒŒì¼ ìƒì„±
cp .env.example .env

# Docker Composeë¡œ ëª¨ë“  ì„œë¹„ìŠ¤ ì‹œì‘
docker-compose up -d

# í—¬ìŠ¤ ì²´í¬
curl http://localhost:8000/health
```

## ğŸ“¡ API ì—”ë“œí¬ì¸íŠ¸

### í—¬ìŠ¤ ì²´í¬
```bash
GET /health
```

### ë™ê¸° ë¶„ì„ (ì‹¤ì‹œê°„ ê²°ê³¼ ë°˜í™˜)
```bash
POST /analyze
Content-Type: application/json

{
  "repo": {
    "source": "git",
    "uri": "https://github.com/user/repo",
    "branch": "main"
  },
  "options": {
    "summary": "llm",
    "graph": "full",
    "metrics": "full"
  },
  "thresholds": {
    "codebleu_min": 0.42,
    "rougeL_min": 0.30
  }
}
```

### ë¹„ë™ê¸° ë¶„ì„ (run_id ë°˜í™˜)
```bash
POST /analyze-async
Content-Type: application/json

{
  "repo": {
    "source": "git",
    "uri": "https://github.com/user/repo"
  }
}

# ì‘ë‹µ
{
  "run_id": "abc-123",
  "status": "queued",
  "message": "Analysis queued..."
}
```

### ê²°ê³¼ ì¡°íšŒ
```bash
GET /result/{run_id}
```

### HTML ë¦¬í¬íŠ¸ ìƒì„±
```bash
GET /report/{run_id}
```

### MCP ìƒíƒœ í™•ì¸
```bash
GET /mcp-status
```

## ğŸ”§ LangGraph ì›Œí¬í”Œë¡œìš°

```
START
  â†“
Parallel Execution:
  â”œâ”€ summarize_node (ìš”ì•½)
  â”œâ”€ build_graph_node (êµ¬ì¡° ë¶„ì„)
  â”œâ”€ embed_code_node (ì„ë² ë”©)
  â””â”€ analyze_repo_node (ì €ì¥ì†Œ ë¶„ì„)
  â†“
evaluate_node (í’ˆì§ˆ í‰ê°€)
  â†“
check_quality (ì¡°ê±´ë¶€ ë¶„ê¸°)
  â”œâ”€ Quality OK â†’ synthesize_node (ìµœì¢… ê²°ê³¼)
  â””â”€ Quality Low â†’ refine_node (ì¬ë¶„ì„) â†’ evaluate_node (ë£¨í”„)
  â†“
END
```

## ğŸ¯ ëª¨ë¸ í†µí•© ê°€ì´ë“œ

ë‹¹ì‹ ì˜ ì»¤ìŠ¤í…€ ëª¨ë¸ì„ í†µí•©í•˜ë ¤ë©´:

### 1. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
```bash
# ë¡œì»¬ì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ìºì‹±
python -c "
from transformers import AutoModel, AutoTokenizer
model = AutoModel.from_pretrained('YOUR_MODEL_ID', cache_dir='models/summarization')
tokenizer = AutoTokenizer.from_pretrained('YOUR_MODEL_ID', cache_dir='models/summarization')
"
```

### 2. Model Loader ìˆ˜ì •
`mcp/{service}/models_loader.py`ì—ì„œ:
```python
def initialize(self):
    self.pool.add_model(
        'your_model_key',
        'local_or_huggingface_path',
        model_type='transformer'
    )
```

### 3. Core Logic ìˆ˜ì •
`mcp/{service}/analyzer.py` ë˜ëŠ” `summarizer.py`ì—ì„œ ëª¨ë¸ í™œìš© ë¡œì§ êµ¬í˜„

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### GPU ì§€ì›
```bash
# docker-compose.ymlì—ì„œ CUDA í™œì„±í™”
environment:
  - DEVICE=cuda  # ë˜ëŠ” cpu
```

### ëª¨ë¸ ì–‘ìí™”
Large ëª¨ë¸ì„ ì–‘ìí™”í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ:
```python
from transformers import AutoModelForSequenceClassification
import torch

model = AutoModelForSequenceClassification.from_pretrained(...)
quantized_model = torch.quantization.quantize_dynamic(
    model, {torch.nn.Linear}, dtype=torch.qint8
)
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
pytest tests/ -v
```

### API í…ŒìŠ¤íŠ¸
```bash
# Swagger UIì—ì„œ í…ŒìŠ¤íŠ¸
http://localhost:8000/docs
```

## ğŸ“ ë¡œê¹…

ê° ì„œë¹„ìŠ¤ëŠ” êµ¬ì¡°í™”ëœ ë¡œê¹…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:

```bash
# ë¡œê·¸ í™•ì¸
docker-compose logs agent-service
docker-compose logs summarization-mcp
```

## ğŸ” ë³´ì•ˆ

- `.env` íŒŒì¼ì— ë¯¼ê°í•œ ì •ë³´ ì €ì¥ (í™˜ê²½ë³€ìˆ˜)
- í”„ë¡œë•ì…˜ì—ì„œëŠ” HTTPS ì‚¬ìš©
- API ì¸ì¦ ì¶”ê°€ ê¶Œì¥ (API Key, JWT ë“±)

## ğŸ“š ë¬¸ì„œ

- `structure.md`: ìƒì„¸ ëª…ì„¸ì„œ
- `RESTAPI/`: ê¸°ì¡´ REST API êµ¬í˜„

## ğŸ¤ ì»¤ìŠ¤í„°ë§ˆì´ì œì´ì…˜

### ìƒˆë¡œìš´ MCP ì¶”ê°€
1. `mcp/new_service/` ë””ë ‰í† ë¦¬ ìƒì„±
2. `main.py`, `analyzer.py`, `models_loader.py`, `Dockerfile` ì‘ì„±
3. `docker-compose.yml`ì— ì„œë¹„ìŠ¤ ì¶”ê°€
4. `agent/nodes.py`ì— ìƒˆ ë…¸ë“œ í•¨ìˆ˜ ì¶”ê°€
5. `agent/workflow.py`ì— ì›Œí¬í”Œë¡œìš° ì—…ë°ì´íŠ¸

### í‰ê°€ ë©”íŠ¸ë¦­ ì»¤ìŠ¤í„°ë§ˆì´ì§•
`agent/nodes.py`ì˜ `evaluate_node`ì—ì„œ ë©”íŠ¸ë¦­ ê³„ì‚° ë°©ì‹ ìˆ˜ì •

## ğŸ› ë¬¸ì œ í•´ê²°

### MCP ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨
```bash
# í—¬ìŠ¤ ì²´í¬
curl http://localhost:9001/health
# ë˜ëŠ” Docker ë‚´ë¶€ì—ì„œ
docker exec summarization-mcp curl http://localhost:9001/health
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±
- ë°°ì¹˜ í¬ê¸° ê°ì†Œ
- ëª¨ë¸ ì–‘ìí™” í™œì„±í™”
- ì„ì‹œ ì €ì¥ì†Œ ì •ë¦¬: `rm -rf /tmp/code_analysis_repos/*`

### GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
import torch
torch.cuda.empty_cache()
```

## ğŸ“„ ë¼ì´ì„ ìŠ¤

[í”„ë¡œì íŠ¸ ë¼ì´ì„ ìŠ¤]

## ğŸ‘¨â€ğŸ’» ê¸°ì—¬

Pull RequestëŠ” í™˜ì˜í•©ë‹ˆë‹¤!