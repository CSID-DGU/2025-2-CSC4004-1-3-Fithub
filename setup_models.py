#!/usr/bin/env python3
"""
AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì„¤ì • ìŠ¤í¬ë¦½íŠ¸.

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ê° MCP ì„œë¹„ìŠ¤ì— í•„ìš”í•œ ëª¨ë¸ë“¤ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì»¤ìŠ¤í…€ ëª¨ë¸ì´ ìˆë‹¤ë©´, í•´ë‹¹ ë¶€ë¶„ì„ ìˆ˜ì •í•˜ì„¸ìš”.
"""

import os
import sys
from pathlib import Path
from typing import Optional

# ëª¨ë¸ ìºì‹œ ë””ë ‰í† ë¦¬
MODELS_DIR = Path(__file__).parent / "models"

# ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
MODELS_CONFIG = {
    "summarization": {
        "codet5": "Salesforce/codet5p-base",
        "starcoder2": "bigcode/starcoder2-3b",
        "codellama": "meta-llama/CodeLlama-7b-Instruct-hf",
        "unixcoder": "microsoft/unixcoder-base",
    },
    "structural_analysis": {
        "graphcodebert": "microsoft/graphcodebert-base",
        "codebert": "microsoft/codebert-base",
    },
    "semantic_embedding": {
        "codebert": "microsoft/codebert-base",
        "cubert": "google/cubert-base-pytorch",
    },
    "repository_analysis": {
        "codebert": "microsoft/codebert-base",
    },
    "task_recommender": {
        "codebert": "microsoft/codebert-base",
    },
}


def setup_model(model_id: str, cache_dir: Path, model_type: str = "transformer") -> bool:
    """
    ë‹¨ì¼ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ìºì‹±í•©ë‹ˆë‹¤.

    Args:
        model_id: HuggingFace ëª¨ë¸ ID
        cache_dir: ìºì‹œ ë””ë ‰í† ë¦¬
        model_type: ëª¨ë¸ íƒ€ì…

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    try:
        print(f"â³ Downloading {model_id}...")

        cache_dir.mkdir(parents=True, exist_ok=True)

        if model_type == "transformer":
            from transformers import AutoModel, AutoTokenizer

            # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
            model = AutoModel.from_pretrained(
                model_id,
                cache_dir=str(cache_dir),
                trust_remote_code=True,
            )

            # í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ
            tokenizer = AutoTokenizer.from_pretrained(
                model_id,
                cache_dir=str(cache_dir),
                trust_remote_code=True,
            )

            print(f"âœ“ {model_id} downloaded successfully")
            return True

    except Exception as e:
        print(f"âœ— Failed to download {model_id}: {e}")
        return False


def setup_all_models(interactive: bool = True) -> None:
    """
    ëª¨ë“  ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        interactive: ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì—¬ë¶€
    """
    print("=" * 60)
    print("Code Analysis Agent - Model Setup")
    print("=" * 60)
    print()

    total_models = sum(len(models) for models in MODELS_CONFIG.values())
    downloaded = 0
    failed = 0

    for service, models in MODELS_CONFIG.items():
        service_dir = MODELS_DIR / service
        print(f"\nğŸ“¦ {service.upper()}")
        print("-" * 40)

        for model_name, model_id in models.items():
            cache_dir = service_dir / model_name

            if cache_dir.exists() and any(cache_dir.iterdir()):
                print(f"  âœ“ {model_name} (already cached)")
                downloaded += 1
                continue

            if interactive:
                response = input(
                    f"  Download {model_name} ({model_id})? [y/n/skip all]: "
                ).lower()

                if response == "skip all":
                    print(f"  âŠ˜ Skipped remaining models in {service}")
                    break
                elif response != "y":
                    continue

            if setup_model(model_id, cache_dir):
                downloaded += 1
            else:
                failed += 1

    print()
    print("=" * 60)
    print(f"Summary: {downloaded}/{total_models} models ready")
    if failed > 0:
        print(f"âš ï¸  {failed} models failed to download")
    print("=" * 60)
    print()

    if downloaded == total_models:
        print("âœ“ All models successfully set up!")
        print()
        print("Next steps:")
        print("  1. Start services: docker-compose up -d")
        print("  2. Run analysis: curl -X POST http://localhost:8000/analyze ...")
    else:
        print("âš ï¸  Some models are missing. Services may have limited functionality.")
        print()
        print("To retry setup:")
        print("  python setup_models.py")


def setup_custom_model(
    service: str,
    model_name: str,
    model_path: str,
) -> bool:
    """
    ì»¤ìŠ¤í…€ ëª¨ë¸ì„ ì„¤ì •í•©ë‹ˆë‹¤.

    Args:
        service: ì„œë¹„ìŠ¤ëª… (summarization, structural_analysis ë“±)
        model_name: ëª¨ë¸ ì´ë¦„
        model_path: ëª¨ë¸ ê²½ë¡œ (ë¡œì»¬ ë˜ëŠ” HuggingFace ID)

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    print(f"Setting up custom model: {model_name} for {service}")

    cache_dir = MODELS_DIR / service / model_name

    return setup_model(model_path, cache_dir, model_type="transformer")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Setup AI models for code analysis agent")
    parser.add_argument(
        "--non-interactive",
        action="store_true",
        help="Download all models without prompting"
    )
    parser.add_argument(
        "--service",
        type=str,
        help="Setup specific service only"
    )
    parser.add_argument(
        "--skip-large",
        action="store_true",
        help="Skip large models (e.g., CodeLlama)"
    )

    args = parser.parse_args()

    try:
        interactive = not args.non_interactive

        # í° ëª¨ë¸ ì œì™¸
        if args.skip_large:
            if "summarization" in MODELS_CONFIG:
                MODELS_CONFIG["summarization"].pop("codellama", None)
                MODELS_CONFIG["summarization"].pop("starcoder2", None)
            print("âŠ˜ Large models skipped")
            print()

        # íŠ¹ì • ì„œë¹„ìŠ¤ë§Œ ì„¤ì •
        if args.service:
            if args.service not in MODELS_CONFIG:
                print(f"Unknown service: {args.service}")
                sys.exit(1)

            service_config = {args.service: MODELS_CONFIG[args.service]}
            MODELS_CONFIG = service_config

        setup_all_models(interactive=interactive)

    except KeyboardInterrupt:
        print("\n\nSetup cancelled by user")
        sys.exit(0)
    except Exception as e:
        print(f"\nError during setup: {e}")
        sys.exit(1)
